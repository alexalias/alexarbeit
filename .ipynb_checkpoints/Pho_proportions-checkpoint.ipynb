{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine phoneme proportions in words of specific length, using a training database\n",
    "Actual exploration starts after defining the sort_dict_val(dict_value_list) function.\n",
    "Each cell has only one function (usually in this order): \n",
    " 1. either it defines a function (usually in order to create or sort a dictionary)\n",
    " 2. or it creates lists that can be used to make nice graphs\n",
    " 3. or it creates graphs from the above created lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import speech_rate\n",
    "from scipy.stats.stats import pearsonr\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the link to the data on which you want to explore\n",
    "# You need it in the two cells defining some sort of build...dictionary, in the line starting with: os.chdir\n",
    "training_db = \"C:/Users/alexutza_a/Abschlussarbeit/DB_Verbmobil/Evaluation/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a dict of phoneme proportions in words of specific lengths (as no of phonemes) - w_dur in msec.\n",
    "# Looks like: {\"a\" : {1pho_w : [w_dur1, pho_prop1, pho_dur1, w_dur2, pho_prop2, ...], 2pho_w : [...], ...}, \n",
    "#              \"b\" : {1pho_w : [w_dur1, pho_prop1, pho_dur1, w_dur2, pho_prop2, ...], 2pho_w: [...], ...}, \n",
    "#               ...}\n",
    "def build_simple_dict():\n",
    "    simple_phoprop_dict = defaultdict(dict) # the dict to be returned\n",
    "    simple_prop_dict = defaultdict(list)   # the value dict\n",
    "    os.chdir(training_db)\n",
    "    \n",
    "    #Iterate over the training files\n",
    "    for datei in glob.glob(\"*.par\"):\n",
    "        work_file = open(datei)\n",
    "        for line in work_file:\n",
    "            if re.match(\"MAU\", line):\n",
    "                w_dur, phon_count, syl_count = speech_rate.word_duration(datei, int(line.split()[3]))\n",
    "                key = str(phon_count)+\"pho_w\"\n",
    "                simple_prop_dict[key].append(round(w_dur*0.0625, 2))                 # w_dur used in msec.\n",
    "                simple_prop_dict[key].append(round(int(line.split()[2])/w_dur, 3))   # calc pho prop as pho_dur/w_dur\n",
    "                #simple_prop_dict[key].append(round(int(line.split()[2])*0.0625), 3)\n",
    "                if key in simple_phoprop_dict[line.split()[4]].keys():\n",
    "                    simple_phoprop_dict[line.split()[4]][key] += simple_prop_dict[key]\n",
    "                else: \n",
    "                    simple_phoprop_dict[line.split()[4]][key] = simple_prop_dict[key]\n",
    "                simple_prop_dict.clear()\n",
    "        work_file.close()\n",
    "    return simple_phoprop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16pho_w': [1009.0, 0.129, 1019.0, 0.128], '3pho_w': [329.81, 0.637, 299.81, 0.533, 249.81, 0.6], '13pho_w': [709.19, 0.183], '5pho_w': [429.69, 0.372, 359.69, 0.417, 239.69, 0.417], '4pho_w': [519.75, 0.5]}\n",
      "Wall time: 7.72 s\n"
     ]
    }
   ],
   "source": [
    "# Example call of the simple phoneme proportions dict\n",
    "%time print(build_simple_dict()[\"OY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Help function for getting name and duration of other long pho in word (vowels & nasals & /x/ & /s/)\n",
    "corr_phonemes = [\"a\", \"a~\", \"e\", \"E\", \"I\", \"i\", \"O\", \"o\", \"U\", \"u\", \"Y\", \"y\", \"9\", \"2\", \"a:\", \"a~:\", \"e:\", \"E:\", \"i:\",\n",
    "                 \"o:\", \"u:\", \"y:\", \"2:\", \"OY\", \"aU\", \"aI\", \"@\", \"6\", \"m\", \"n\", \"N\", \"x\", \"s\"]\n",
    "def get_longP(datei, word_no, zeile):\n",
    "    work_file = open(datei)\n",
    "    long_Plist = []\n",
    "    z = 0\n",
    "    for line in work_file:\n",
    "        if re.match(\"MAU\", line) and word_no == int(line.split()[3]):\n",
    "            if (line.split()[4] in corr_phonemes) and (z != zeile):\n",
    "                w_dur, phon_count, syl_count = speech_rate.word_duration(datei, int(line.split()[3]))\n",
    "                #print(\"z: \" + str(z))\n",
    "                #print(\"zeile: \" + str(zeile))\n",
    "                long_Plist.append(line.split()[4])\n",
    "                long_Plist.append(round(int(line.split()[2])/w_dur, 3))\n",
    "            elif z == zeile:\n",
    "                continue\n",
    "        z += 1\n",
    "    work_file.close()\n",
    "    return long_Plist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a dict of phoneme proportions in words of specific lengths (as no of phonemes) - w_dur in msec.\n",
    "# It considers also the presence of other correlating phonemes in word\n",
    "# Looks like: {\"a\" : {1pho_w : [filename, word_nr, 0, [], w_dur2, pho_dur2, ...], \n",
    "#                     2pho_w : [w_dur1, pho_dur1, no._other_long_pho, [otherPho1, prop_otherPho1, ...], w_dur2, pho_dur2, [...], ...}, \n",
    "#              \"b\" : {1pho_w : [w_dur1, pho_dur1, 0, [], w_dur2, pho_dur2, ...], 2pho_w: [...], ...}, \n",
    "#               ...}\n",
    "def build_complex_dict():\n",
    "    simple_phoprop_dict = defaultdict(dict) # the dict to be returned\n",
    "    simple_prop_dict = defaultdict(list)   # the value dict\n",
    "    \n",
    "    os.chdir(training_db)\n",
    "    \n",
    "    #Iterate over the training files\n",
    "    for datei in glob.glob(\"*.par\"):\n",
    "        work_file = open(datei)\n",
    "        zeile = 0                              # a row counter; counting starts at beginning of file\n",
    "        for line in work_file:\n",
    "            if re.match(\"MAU\", line):\n",
    "                w_dur, phon_count, syl_count = speech_rate.word_duration(datei, int(line.split()[3]))\n",
    "                key = str(phon_count)+\"pho_w\"\n",
    "                simple_prop_dict[key].append(str(datei)[-20:])       # file name \n",
    "                simple_prop_dict[key].append(int(line.split()[3]))   # word number\n",
    "                simple_prop_dict[key].append(str(line.split()[4]))   # phoneme\n",
    "                simple_prop_dict[key].append(round(w_dur*0.0625, 2))                 # w_dur used in msec.\n",
    "                simple_prop_dict[key].append(round(int(line.split()[2])/w_dur, 3))   # calc pho prop as pho_dur/w_dur\n",
    "                simple_prop_dict[key].append(get_longP(datei, int(line.split()[3]), zeile))  # list of other pho in word\n",
    "                if key in simple_phoprop_dict[line.split()[4]].keys():\n",
    "                    simple_phoprop_dict[line.split()[4]][key] += simple_prop_dict[key]\n",
    "                else: \n",
    "                    simple_phoprop_dict[line.split()[4]][key] = simple_prop_dict[key]\n",
    "                simple_prop_dict.clear()\n",
    "            zeile += 1\n",
    "        work_file.close()\n",
    "    return simple_phoprop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16pho_w': ['g376acn2_009_AKX.par', 28, 'OY', 1009.0, 0.129, ['n', 0.059], 'g376acn2_069_AKX.par', 13, 'OY', 1019.0, 0.128, ['n', 0.039]], '3pho_w': ['g376acn2_030_AKX.par', 34, 'OY', 329.81, 0.637, ['n', 0.182], 'g376acn2_035_AKX.par', 15, 'OY', 299.81, 0.533, ['n', 0.133], 'g378acn2_028_AKX.par', 5, 'OY', 249.81, 0.6, ['n', 0.24]], '13pho_w': ['g376acn2_041_AKX.par', 3, 'OY', 709.19, 0.183, ['n', 0.085]], '5pho_w': ['g378acn2_014_AKX.par', 29, 'OY', 429.69, 0.372, ['n', 0.093], 'g378acn2_102_AKX.par', 0, 'OY', 359.69, 0.417, ['n', 0.139], 'g378acn2_102_AKX.par', 3, 'OY', 239.69, 0.417, ['n', 0.208]], '4pho_w': ['g379acn2_106_AKX.par', 1, 'OY', 519.75, 0.5, []]}\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "# Example call of the complex phoneme proportions dict\n",
    "%time print(build_complex_dict()[\"OY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "# Build the simple phoneme proportions dictionary\n",
    "%time simple_pprop_dict = build_simple_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "# Bild the complex phoneme proportions dictionary\n",
    "%time complex_pprop_dict = build_complex_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# sort needed dict_list from the simple (!) dict\n",
    "def sort_dict_val(dict_value_list):\n",
    "#    dict_value_list = simple_pprop_dict[\"a:\"][\"2pho_w\"]\n",
    "    l_gr = [dict_value_list[i:i+2] for i in range(0, len(dict_value_list),2)] # transform list in list of 2-elem-lists\n",
    "    l_sorted = sorted(l_gr,key=itemgetter(0)) # sort list of of 2-elem-lists\n",
    "    org_simpleDict_val = []\n",
    "    for i in range(len(l_sorted)):    # flatten sorted list\n",
    "        org_simpleDict_val += l_sorted[i]\n",
    "    return org_simpleDict_val\n",
    "#print(sort_dict_val(simple_pprop_dict[\"a:\"][\"2pho_w\"])[:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cf74f660b228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Test data for plot /a:/-durations in 2pho_w against w_dur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimple_wdur_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort_dict_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplex_pprop_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"a:\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2pho_w\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;31m#simple_wdur_list = [ round(x/1000, 3) for x in simple_wdur_list]     #transform w_dur in sec (from msec)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msimple_pdur_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort_dict_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplex_pprop_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"a:\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2pho_w\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_pdur_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-32df816b4dac>\u001b[0m in \u001b[0;36msort_dict_val\u001b[0;34m(dict_value_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#    dict_value_list = simple_pprop_dict[\"a:\"][\"2pho_w\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ml_gr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdict_value_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_value_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# transform list in list of 2-elem-lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ml_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_gr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sort list of of 2-elem-lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0morg_simpleDict_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# flatten sorted list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Test data for plot /a:/-durations in 2pho_w against w_dur\n",
    "simple_wdur_list = sort_dict_val(complex_pprop_dict[\"a:\"][\"2pho_w\"])[0::4]\n",
    "#simple_wdur_list = [ round(x/1000, 3) for x in simple_wdur_list]     #transform w_dur in sec (from msec)\n",
    "simple_pdur_list = sort_dict_val(complex_pprop_dict[\"a:\"][\"2pho_w\"])[1::4]\n",
    "print(len(simple_pdur_list))\n",
    "print(simple_pdur_list[:5])\n",
    "print(simple_wdur_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test data for plot /a:/-proportions in 2pho_w against w_dur\n",
    "simple_dur_list = sort_dict_val(simple_pprop_dict[\"a:\"][\"2pho_w\"])[::2]\n",
    "simple_dur_list = [ round(x/1000, 3) for x in simple_dur_list]     #transform w_dur in sec (from msec)\n",
    "simple_prop_list = sort_dict_val(simple_pprop_dict[\"a:\"][\"2pho_w\"])[1::2]\n",
    "print(len(simple_dur_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Graph shows that the duration of /a:/ in 2-phoneme-words correlates very well with word duration\n",
    "x = range(100)\n",
    "plt.plot(x, simple_wdur_list, label = \"word duration (ms)\")\n",
    "plt.plot(x, simple_pdur_list, label = \"duration of /a:/ (ms)\")\n",
    "plt.title(\"Duration of /a:/ vs. increasing duration of 2-phon-long words\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This scatter plot confirms the result of the previous plot\n",
    "print(\"Pearson correlation coefficient for /a:/ in 2-phoneme-long words:\")\n",
    "print(pearsonr(simple_pdur_list, simple_wdur_list)[0])\n",
    "m, b = np.polyfit(simple_pdur_list, simple_wdur_list,1) # elem. of the regression function\n",
    "plt.scatter(simple_pdur_list, simple_wdur_list, color = \"darkorange\")\n",
    "plt.plot((np.unique(simple_pdur_list)), (m*(np.unique(simple_pdur_list)) + b), \"-\", color=\"k\") # plot regression line\n",
    "plt.xlabel(\"Duration of /a:/ in msec\")\n",
    "plt.ylabel(\"Word duration in msec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Graph shows that the proportion of /a:/ in 2-phoneme-words doesn't correlate with word duration\n",
    "x = range(100)\n",
    "plt.plot(x, simple_dur_list, label = \"word duration (s)\")\n",
    "plt.plot(x, simple_prop_list, label = \"proportion of /a:/\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This scatter plot confirms the result of the previous plot\n",
    "print(pearsonr(simple_prop_list, simple_dur_list))\n",
    "plt.scatter(simple_prop_list, simple_dur_list, color = \"darkorange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Would suggest it makes sense to use only the interquartile area, or even just the mean/median value\n",
    "plt.boxplot(simple_prop_list, labels = [\"a:\"], showmeans=True)\n",
    "plt.show()\n",
    "print(\"Median: \" + str(np.median(simple_prop_list)))\n",
    "print(\"Mean: \" + str(np.mean(simple_prop_list)))\n",
    "Q1 = np.percentile(simple_prop_list, 25)\n",
    "Q3 = np.percentile(simple_prop_list, 75)\n",
    "print(\"Q1: \" + str(Q1) + \"   Q3: \" + str(Q3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This plot confirms the intuition, that the percent occupied by /a:/ decreases with length of word (as # of phonemes)\n",
    "# Boxplot with /a:/-proportions overview on all word legths\n",
    "prop_lists = []\n",
    "\n",
    "# sort data by increasing word length\n",
    "key_list = sorted(simple_pprop_dict[\"a:\"].keys())\n",
    "first_3 = key_list[:3]\n",
    "key_list = key_list[3:] + first_3\n",
    "\n",
    "# generate list of lists for plotting\n",
    "for el in key_list:\n",
    "    prop_lists.append(simple_pprop_dict[\"a:\"][el][1::2])\n",
    "\n",
    "# create a list of count/word-length\n",
    "count_list = []\n",
    "for el in prop_lists:\n",
    "    count_list.append(len(el))\n",
    "\n",
    "# actually plot data\n",
    "plt.figure(figsize=(25, 17))\n",
    "plt.boxplot(prop_lists, labels = key_list, showmeans=True)\n",
    "plt.title(\"Proportion variation of /a:/ at different word lengths\")\n",
    "plt.show()\n",
    "print(count_list)\n",
    "# print some boxplot relevant info (median, mean, Q1, Q3)\n",
    "for el in prop_lists:   \n",
    "    print(key_list[prop_lists.index(el)] + \":\")\n",
    "    Q1 = np.percentile(el, 25)\n",
    "    Q3 = np.percentile(el, 75)\n",
    "    print(\"  Median: \" + str(round(np.median(el), 3)) + \" Mean: \" + str(round(np.mean(el), 3)) + \n",
    "          \" Q1: \" + str(round(Q1, 3)) + \"   Q3: \" + str(round(Q3, 3)))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test data for plot /a:/-durations in 3pho_w against w_dur\n",
    "simple_w3dur_list = sort_dict_val(simple_ddict[\"a:\"][\"3pho_w\"])[::2]\n",
    "#simple_wdur_list = [ round(x/1000, 3) for x in simple_wdur_list]     #transform w_dur in sec (from msec)\n",
    "simple_p3dur_list = sort_dict_val(simple_ddict[\"a:\"][\"3pho_w\"])[1::2]\n",
    "#print(len(simple_p3dur_list))\n",
    "print(simple_pdur_list[:5])\n",
    "print(simple_wdur_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This scatter plot confirms the result of the previous plot\n",
    "print(pearsonr(simple_p3dur_list, simple_w3dur_list)[0])\n",
    "m, b = np.polyfit(simple_p3dur_list, simple_w3dur_list,1) # elem. of the regression function\n",
    "plt.scatter(simple_p3dur_list, simple_w3dur_list, color = \"darkorange\")\n",
    "plt.plot((np.unique(simple_p3dur_list)), (m*(np.unique(simple_p3dur_list)) + b), \"-\", color=\"k\") # plot regression line\n",
    "plt.xlabel(\"Duration of /a:/ in msec\")\n",
    "plt.ylabel(\"Word duration in msec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "# sort needed dict_list from the complex dict\n",
    "complex_dict_la2p = complex_pprop_dict[\"a:\"][\"2pho_w\"]\n",
    "l_gr = [complex_dict_la2p[i:i+6] for i in range(0, len(complex_dict_la2p),6)] # transform list in list of 2-elem-lists\n",
    "l_sorted = sorted(l_gr,key=itemgetter(3)) # sort list of of 2-elem-lists\n",
    "org_complexDict_la2p = []\n",
    "for i in range(len(l_sorted)):    # flatten sorted list\n",
    "    org_complexDict_la2p += l_sorted[i]\n",
    "print(org_complexDict_la2p[:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
